{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECE 247A - Design Matrix\n",
    "# imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scienceplots\n",
    "import shutup\n",
    "\n",
    "from glm import build_model\n",
    "from data import add_sigmoid_params\n",
    "\n",
    "from renderers import *\n",
    "from neuron_viewer import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# pretty plots\n",
    "plt.style.use(['nature'])\n",
    "plt.rcParams['figure.dpi'] = 200\n",
    "%matplotlib widget\n",
    "\n",
    "# suppress warnings :-)\n",
    "shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# 2. rerun and save dmat OR refactor to make cleaner \n",
    "# 3. add search to neuronviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "trial_data_all = np.load(\"../vars/trial_data_all_MM012_MM013_all5.npz\", allow_pickle=True)['arr_0']\n",
    "session_data_all = np.load(\"../vars/session_data_all_MM012_MM013_all5.npz\", allow_pickle=True)['arr_0']\n",
    "unit_spike_times_all = np.load(\"../vars/unit_spike_times_all_MM012_MM013_all5.npz\", allow_pickle=True)['arr_0']\n",
    "regions_all = np.load(\"../vars/regions_all_MM012_MM013_all5.npz\", allow_pickle=True)['arr_0']\n",
    "\n",
    "MB_sig_sess = np.load(\"../vars/MB_sigs_sess.npz\", allow_pickle=True)['arr_0']\n",
    "MF_sig_sess = np.load(\"../vars/MF_sigs_sess.npz\", allow_pickle=True)['arr_0']\n",
    "\n",
    "subj_idx = 0\n",
    "learner = 'early' #'late'\n",
    "sess_idx = 0 if learner=='early' else 9 # 0 and 9\n",
    "\n",
    "trial_data = trial_data_all[subj_idx][sess_idx]\n",
    "session_data = session_data_all[subj_idx][sess_idx]\n",
    "spike_times = unit_spike_times_all[subj_idx][sess_idx]['ACC']\n",
    "mb_sigms = MB_sig_sess[sess_idx]\n",
    "mf_sigms = MF_sig_sess[sess_idx]\n",
    "\n",
    "trial_data = add_sigmoid_params(trial_data, session_data, mb_sigms, mf_sigms)\n",
    "\n",
    "corrected_onset = np.load(f'../vars/MM012_{learner}_corrected_onsets.npy', allow_pickle=True)\n",
    "vidtime = corrected_onset.item()[5]\n",
    "svds = np.load(f'../vars/MM012_{learner}_video_SVD.npy', allow_pickle=True)[1]\n",
    "\n",
    "from scipy.stats import zscore\n",
    "svds_zscore = zscore(svds, axis=1)\n",
    "\n",
    "mn = trial_data['task_start_time'].values.min()\n",
    "mx = trial_data['task_start_time'].values.max()\n",
    "\n",
    "vidtime = ((vidtime/1e3) * (mx-mn)/max(vidtime/1e3)) + mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make design matrix\n",
    "\n",
    "BWMS = 10\n",
    "binwidth_s = BWMS/1000\n",
    "\n",
    "responded = (trial_data['response']==1) | (trial_data['response']==-1)\n",
    "master_alignment_times = trial_data['task_start_time'] + trial_data['response_time']\n",
    "master_alignment_times = master_alignment_times[responded].values\n",
    "\n",
    "pres = 1\n",
    "posts = 2\n",
    "bwidth = BWMS / 1000\n",
    "\n",
    "dmat = build_model(master_alignment_times, trial_data, svds_zscore, vidtime, pres=pres, posts=posts, bwidth=binwidth_s)\n",
    "dmat.build_matrix()\n",
    "X = dmat.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the cell responds to right contrasts\n",
    "\n",
    "from DAMN.damn.alignment import compute_spike_count\n",
    "from spks.viz import plot_event_aligned_raster\n",
    "from spks.utils import gaussian_function\n",
    "\n",
    "r_mask = (trial_data[responded]['response']==-1)\n",
    "l_mask = (trial_data[responded]['response']==1)\n",
    "w_mask = (trial_data[responded]['rewarded']==1)\n",
    "p_mask = (trial_data[responded]['rewarded']==0)\n",
    "\n",
    "all = []\n",
    "all_l = []\n",
    "all_r = []\n",
    "all_w = []\n",
    "all_p = []\n",
    "for s in spike_times:\n",
    "    peth, timebin_centers, event_ind       = compute_spike_count(master_alignment_times, s, pre_seconds=pres, post_seconds=posts, binwidth_s=BWMS/1000)\n",
    "    peth_l, timebin_centers_l, event_ind_l = compute_spike_count(master_alignment_times[l_mask], s, pre_seconds=pres, post_seconds=posts, binwidth_s=BWMS/1000)\n",
    "    peth_r, timebin_centers_r, event_ind_r = compute_spike_count(master_alignment_times[r_mask], s, pre_seconds=pres, post_seconds=posts, binwidth_s=BWMS/1000)\n",
    "    peth_w, timebin_centers_w, event_ind_w = compute_spike_count(master_alignment_times[w_mask], s, pre_seconds=pres, post_seconds=posts, binwidth_s=BWMS/1000)\n",
    "    peth_p, timebin_centers_p, event_ind_p = compute_spike_count(master_alignment_times[p_mask], s, pre_seconds=pres, post_seconds=posts, binwidth_s=BWMS/1000)\n",
    "    \n",
    "    all.append(peth)\n",
    "    all_l.append(peth_l)\n",
    "    all_r.append(peth_r)\n",
    "    all_w.append(peth_w)\n",
    "    all_p.append(peth_p)\n",
    "    \n",
    "peth = np.stack(all)\n",
    "peth_l = np.stack(all_l)\n",
    "peth_r = np.stack(all_r)\n",
    "peth_w = np.stack(all_w)\n",
    "peth_p = np.stack(all_p)\n",
    "\n",
    "n_units, n_trials, samples_per_trial = peth.shape\n",
    "_, n_trials_l, _ = peth_l.shape\n",
    "_, n_trials_r, _ = peth_r.shape\n",
    "_, n_trials_w, _ = peth_w.shape # w stands for water... rewarded overloads r for right\n",
    "_, n_trials_p, _ = peth_p.shape\n",
    "\n",
    "print(\"num trials: \", n_trials, \n",
    "      \", num left trials: \", n_trials_l, \n",
    "      \", num right trials: \", n_trials_r, \n",
    "      \", num rewarded trials: \", n_trials_w,\n",
    "      \", num punished trials: \", n_trials_p,\n",
    "      \", samples per trial: \", samples_per_trial)\n",
    "Y = np.reshape(peth, (n_units, n_trials*samples_per_trial,), order='C').T\n",
    "print(\"X shape: \", X.shape, \", Y shape: \", Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuron_viewer import *\n",
    "from renderers import *\n",
    "\n",
    "# r_grand = PETHRenderer(peth, pres, posts, binwidth_s, mode=\"grand\")\n",
    "# viewer_grand = NeuronViewer(num_units=peth.shape[0], render_func=r_grand, ymin=r_grand.ymin, ymax=r_grand.ymax)\n",
    "\n",
    "r_choice = PETHRenderer(\n",
    "    peth_a=peth_l,\n",
    "    peth_b=peth_r,\n",
    "    mode=\"cond\",\n",
    "    label_a=\"left\",\n",
    "    label_b=\"right\"\n",
    ")\n",
    "viewer_choice = NeuronViewer(num_units=peth.shape[0], render_func=r_choice, ymin=r_choice.ymin, ymax=r_choice.ymax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "r_fback = PETHRenderer(\n",
    "    peth_a=peth_w,\n",
    "    peth_b=peth_p,\n",
    "    mode=\"cond\",\n",
    "    label_a=\"reward\",\n",
    "    label_b=\"punish\"\n",
    ")\n",
    "viewer_fback = NeuronViewer(num_units=peth.shape[0], render_func=r_fback, ymin=r_fback.ymin, ymax=r_fback.ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(dmat.X, aspect='auto', vmin=-20, vmax=20)#, vmin=0, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PoissonRegressor, Ridge, LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# now fit models and get coefficients back\n",
    "model = PoissonRegressor(alpha=0)\n",
    "model = MultiOutputRegressor(PoissonRegressor(alpha=1e-7,max_iter=10000), n_jobs=20) #TODO: penalize\n",
    "#model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "#coefs = model.coef_.flatten()\n",
    "bias = [m.intercept_ for m in model.estimators_]\n",
    "coefs = [np.array(m.coef_).flatten() for m in model.estimators_]\n",
    "bias = np.squeeze(bias)\n",
    "if np.ndim(bias) == 0:\n",
    "    bias = np.array([bias])\n",
    "coefs = np.stack(coefs)\n",
    "\n",
    "print(Y.shape, X.shape, coefs.T.shape)\n",
    "\n",
    "dmat.set_coefficients(coefs.T) # ~ 9m 16s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_kernel = KernelRenderer(model, dmat, bias)\n",
    "viewer_kernels = NeuronViewer(num_units=peth.shape[0], render_func=r_kernel, ncols=len(r_kernel.all_tags))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraneous (for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from damn.scoring import bits_per_spike_multi_target\n",
    "bits_per_spike_multi_target(Y, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check best alpha for single cells\n",
    "from damn.scoring import bits_per_spike\n",
    "from sklearn.model_selection import train_test_split\n",
    "ind = -4\n",
    "alphas = np.logspace(-8, 0, 10)\n",
    "scores = []\n",
    "\n",
    "Xsmall = X[:1000]\n",
    "Ysmall = Y[:1000,ind]\n",
    "\n",
    "for a in tqdm(alphas):\n",
    "    model = PoissonRegressor(alpha=a, max_iter=10000)\n",
    "    # randomly split into train and test\n",
    "    model.fit(Xsmall, Ysmall)\n",
    "    Y_pred = model.predict(Xsmall)\n",
    "    scores.append(bits_per_spike(Ysmall, Y_pred))\n",
    "\n",
    "best_alpha = alphas[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha # seems like 1e-5 to 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(alphas,scores)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.metrics import make_scorer\n",
    "from damn.scoring import bits_per_spike_multi_target\n",
    "\n",
    "base_model = PoissonRegressor(max_iter=1000)\n",
    "multi_model = MultiOutputRegressor(base_model)\n",
    "\n",
    "param_dist = {\n",
    "    \"estimator__alpha\": loguniform(1e-6, 1e2)  # IMPORTANT: prefix with estimator__\n",
    "}\n",
    "\n",
    "scorer = make_scorer(\n",
    "    bits_per_spike,\n",
    "    greater_is_better=True\n",
    ")\n",
    "scorer = 'neg_mean_poisson_deviance'\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    multi_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring=scorer,\n",
    "    #n_jobs=-1,\n",
    ")\n",
    "\n",
    "search.fit(X, Y)   # Y shape (n_samples, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "np-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
