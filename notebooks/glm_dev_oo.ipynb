{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from damn import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the cell responds to right contrasts\n",
    "\n",
    "from damn.alignment import compute_spike_count\n",
    "from spks.viz import plot_event_aligned_raster\n",
    "from spks.utils import gaussian_function\n",
    "\n",
    "#BWMS = 1\n",
    "BWMS = 3\n",
    "BWMS = 5\n",
    "#BWMS = 25\n",
    "#BWMS = 100\n",
    "master_alignment_times = trials.stimOn_times\n",
    "pres = .5\n",
    "posts = 1.4\n",
    "bwidth = BWMS / 1000\n",
    "\n",
    "all = []\n",
    "for s in spike_times:\n",
    "    peth, timebin_centers, event_ind = compute_spike_count(master_alignment_times, s, pre_seconds=pres, post_seconds=posts, binwidth_s=BWMS/1000)\n",
    "    all.append(peth)\n",
    "peth = np.stack(all)\n",
    "n_units, n_trials, samples_per_trial = peth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n_trials, samples_per_trial)\n",
    "Y = np.reshape(peth, (n_units, n_trials*samples_per_trial,), order='C').T\n",
    "#Y = np.hstack([Y, np.ones_like(Y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(dmat[2000:4000,:], aspect='auto',interpolation='none')\n",
    "c = 10\n",
    "im = plt.imshow(dmat[0000:4000,:], aspect='auto',interpolation='none', clim=(0,c))\n",
    "# add colorbar\n",
    "plt.colorbar(im)\n",
    "#plt.imshow(X[0000:20000,:], aspect='auto',interpolation='none')\n",
    "#plt.imshow(X[2000:2050,:], aspect='auto',interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PoissonRegressor, Ridge, LinearRegression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "# now fit models and get coefficients back\n",
    "model = PoissonRegressor(alpha=0)\n",
    "model = MultiOutputRegressor(PoissonRegressor(alpha=1e-7,max_iter=10000), n_jobs=1) #TODO: penalize\n",
    "#model = LinearRegression()\n",
    "model.fit(X, Y)\n",
    "#coefs = model.coef_.flatten()\n",
    "bias = [m.intercept_ for m in model.estimators_]\n",
    "coefs = [np.array(m.coef_).flatten() for m in model.estimators_]\n",
    "bias = np.squeeze(bias)\n",
    "if np.ndim(bias) == 0:\n",
    "    bias = np.array([bias])\n",
    "coefs = np.stack(coefs)\n",
    "\n",
    "# zscore columns for speed?\n",
    "#Yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now crossvalidate this\n",
    "#from sklearn.model_selection import KFold, cross_val_score\n",
    "#kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "#model = PoissonRegressor(alpha=0)\n",
    "#Ycval = Y[:,1:3]\n",
    "#for i in range(Ycval.shape[1]):\n",
    "#    scores = cross_val_score(model, X, Ycval[:,i], cv=kf, scoring='d2_absolute_error_score', n_jobs=5)\n",
    "#    print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(Y.shape[1]):\n",
    "#    model.fit(X,Y[:,i])\n",
    "#    print(model.score(X,Y[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape, X.shape, coefs.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmat.set_coefficients(coefs.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmat.right_stim.kernel_summary() , dmat.regressor_summary()\n",
    "#dmat.regressor_summary(tag='stimulus')\n",
    "#xx = dmat.X_for_tag('stimulus')\n",
    "#coef = dmat.coefficients_for_tag('stimulus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot kernels\n",
    "ind = -6\n",
    "\n",
    "linkfunc = model.estimators_[0]._base_loss.link.inverse\n",
    "# get the unique tags from dmat\n",
    "all_tags = []\n",
    "for regname,reg in dmat.regressors.items():\n",
    "    all_tags.extend(reg.tags)\n",
    "all_tags = np.unique(all_tags)\n",
    "all_tags = [t for t in all_tags if t != 'task']\n",
    "all_tags = [t for t in all_tags if t != 'interaction']\n",
    "\n",
    "# make subplots for each tag\n",
    "fig, axs = plt.subplots(1,len(all_tags), figsize=(25,5), sharey=True)\n",
    "if len(all_tags) == 1:\n",
    "    axs = [axs]\n",
    "\n",
    "for i,tag in enumerate(all_tags):\n",
    "    regs = dmat.select(tag=tag)\n",
    "    for r,reg in regs.items():\n",
    "        k,t = reg.reconstruct_kernel()\n",
    "        k = k[:,ind]\n",
    "        k = linkfunc(k + bias[ind])\n",
    "        axs[i].plot(t, k, label=reg.name)\n",
    "    axs[i].set_title(tag)\n",
    "    if tag not in ['history','dlc','video']:\n",
    "        axs[i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "print(query.fetch('probe_num','unit_id',as_dict=True)[ind])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from damn.crossval import bits_per_spike_multi_target\n",
    "bits_per_spike_multi_target(Y, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check best alpha for single cells\n",
    "from damn.crossval import bits_per_spike\n",
    "from sklearn.model_selection import train_test_split\n",
    "ind = -4\n",
    "alphas = np.logspace(-8, 0, 10)\n",
    "scores = []\n",
    "\n",
    "Xsmall = X[:1000]\n",
    "Ysmall = Y[:1000,ind]\n",
    "\n",
    "for a in tqdm(alphas):\n",
    "    model = PoissonRegressor(alpha=a, max_iter=10000)\n",
    "    # randomly split into train and test\n",
    "    model.fit(Xsmall, Ysmall)\n",
    "    Y_pred = model.predict(Xsmall)\n",
    "    scores.append(bits_per_spike(Ysmall, Y_pred))\n",
    "\n",
    "best_alpha = alphas[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_alpha # seems like 1e-5 to 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(alphas,scores)\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import PoissonRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "from sklearn.metrics import make_scorer\n",
    "from damn.crossval import bits_per_spike_multi_target\n",
    "\n",
    "base_model = PoissonRegressor(max_iter=1000)\n",
    "multi_model = MultiOutputRegressor(base_model)\n",
    "\n",
    "param_dist = {\n",
    "    \"estimator__alpha\": loguniform(1e-6, 1e2)  # IMPORTANT: prefix with estimator__\n",
    "}\n",
    "\n",
    "scorer = make_scorer(\n",
    "    bits_per_spike,\n",
    "    greater_is_better=True\n",
    ")\n",
    "scorer = 'neg_mean_poisson_deviance'\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    multi_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring=scorer,\n",
    "    #n_jobs=-1,\n",
    ")\n",
    "\n",
    "search.fit(X, Y)   # Y shape (n_samples, n_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "np-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
